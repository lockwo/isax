{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>isax is a JAX-based library for sampling from Ising models using blocked Gibbs sampling. It supports hypergraphs, flexible sampling/modeling, and all the usual JAX transformations. isax is heavily inspired by thrml and isingtorch.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>git clone https://github.com/lockwo/isax\ncd isax\npip install -e .\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you use ISAX in your research, please cite:</p>"},{"location":"api/block/","title":"Block Graph Tools","text":""},{"location":"api/block/#isax.block.Node","title":"<code>isax.block.Node</code>","text":"<p>Graph node with auto-incrementing ID for unique identification.</p>"},{"location":"api/block/#isax.block.Edge","title":"<code>isax.block.Edge</code>","text":"<p>Edge connecting 2 or more nodes (supports hyperedges).</p>"},{"location":"api/block/#isax.block.Edge.__init__","title":"<code>__init__(*nodes)</code>","text":""},{"location":"api/block/#isax.block.EqxGraph","title":"<code>isax.block.EqxGraph</code>","text":"<p>Stores node-to-index mappings for efficient array operations.</p> <p>The dictionaries restrict batching over different graph topologies.</p>"},{"location":"api/block/#isax.block.BlockGraph","title":"<code>isax.block.BlockGraph</code>","text":"<p>General block graph structure for efficient block-wise operations.</p> <p>A graph G = (V, E) where vertices are organized into blocks for parallelized computation.</p>"},{"location":"api/block/#isax.block.BlockGraph.__init__","title":"<code>__init__(blocks: list[list[isax.block.Node]], edges: list[isax.block.Edge])</code>","text":""},{"location":"api/block/#isax.block.BlockGraph.get_edge_structure","title":"<code>get_edge_structure() -&gt; tuple[jaxtyping.Int[Array, 'num_edges max_k'], jaxtyping.Int[Array, 'num_edges max_k']]</code>","text":"<p>Convert edge list to padded array representation.</p>"},{"location":"api/block/#isax.block.BlockGraph.get_sampling_params","title":"<code>get_sampling_params() -&gt; tuple[tuple[list[jaxtyping.Int[Array, 'num_nodes max_edges max_k-1']], list[jaxtyping.Int[Array, 'num_nodes max_edges max_k-1']], list[jaxtyping.Int[Array, 'num_nodes max_edges']]], isax.block.EqxGraph]</code>","text":"<p>Generate all parameters needed for graph sampling.</p>"},{"location":"api/metrics/","title":"Metrics","text":"<p>Functions for computing physical observables and metrics from sampled states.</p>"},{"location":"api/metrics/#isax.metrics.magnetization_per_site","title":"<code>isax.metrics.magnetization_per_site(state: list[jaxtyping.Int[Array, 'samples block_nodes']]) -&gt; list[jaxtyping.Float[Array, block_nodes]]</code>","text":"<p>Compute magnetization per site.</p> \\[m_j = \\frac{1}{N} \\sum_{i=1}^{N} s_{i,j}\\] <p>Arguments:</p> <ul> <li><code>state</code>: List of arrays, shape <code>(samples, block_nodes)</code> per block.</li> </ul> <p>Returns:</p> <p>List of arrays, shape <code>(block_nodes,)</code> per block.</p>"},{"location":"api/sample/","title":"Sampling","text":""},{"location":"api/sample/#models","title":"Models","text":""},{"location":"api/sample/#isax.sample.IsingModel","title":"<code>isax.sample.IsingModel</code>","text":"<p>Ising model with arbitrary edge interactions and local fields.</p>"},{"location":"api/sample/#isax.sample.IsingModel.energy","title":"<code>energy(state: Int[Array, num_nodes], edge_indices: Int[Array, 'num_edges max_k'], edge_mask: Int[Array, 'num_edges max_k']) -&gt; Float[Array, '']</code>","text":"<p>Compute Ising energy.</p> \\[H = -\\sum_{e \\in E} J_e \\prod_{i \\in e} s_i - \\sum_i h_i s_i\\] <p>Arguments:</p> <ul> <li><code>state</code>: Node spins, shape <code>(num_nodes,)</code>.</li> <li><code>edge_indices</code>: Node indices for each edge, shape <code>(num_edges, max_k)</code>.</li> <li><code>edge_mask</code>: Valid positions in <code>edge_indices</code>.</li> </ul> <p>Returns:</p> <p>Scalar energy.</p>"},{"location":"api/sample/#isax.sample.IsingModel.to_sample_params","title":"<code>to_sample_params(graph: EqxGraph, edge_info: list[jaxtyping.Int[Array, 'nodes max_edges']]) -&gt; list[tuple[jaxtyping.Float[Array, num_edges], jaxtyping.Float[Array, num_nodes]]]</code>","text":"<p>Extract weights and biases for each block.</p> <p>Arguments:</p> <ul> <li><code>graph</code>: Graph structure.</li> <li><code>edge_info</code>: Edge indices per block.</li> </ul> <p>Returns:</p> <p>List of <code>(edge_weights, node_biases)</code> tuples.</p>"},{"location":"api/sample/#samplers","title":"Samplers","text":""},{"location":"api/sample/#isax.sample.AbstractSampler","title":"<code>isax.sample.AbstractSampler</code>","text":"<p>Base class for block-wise sampling algorithms.</p>"},{"location":"api/sample/#isax.sample.IsingSampler","title":"<code>isax.sample.IsingSampler</code>","text":"<p>Gibbs sampler for Ising model at fixed temperature (\\(\\beta=1\\)).</p>"},{"location":"api/sample/#isax.sample.IsingSampler.sample","title":"<code>sample(current_state: Int[Array, num_nodes], neighbor_states: Int[Array, 'num_nodes max_edges max_k-1'], neighbor_mask: Int[Array, 'num_nodes max_edges max_k-1'], model_params: tuple[jaxtyping.Float[Array, num_edges], jaxtyping.Float[Array, num_nodes]], runtime_params: None, sampler_state: None, key: Key[Array, '']) -&gt; tuple[jaxtyping.Int[Array, num_nodes], None]</code>","text":"<p>Parallel Gibbs sampling for all nodes in block.</p> <p>For each node \\(i\\), the effective field is computed as:</p> \\[h_i^{\\text{eff}} = h_i + \\sum_{e \\ni i} J_e \\prod_{j \\in e \\setminus i} s_j\\] <p>The probability of spin \\(s_i = +1\\) is then:</p> \\[P(s_i = +1) = \\sigma(2h_i^{\\text{eff}}) = \\frac{1}{1 + e^{-2h_i^{\\text{eff}}}}\\] <p>where \\(\\sigma\\) is the sigmoid function.</p> <p>Arguments:</p> <ul> <li><code>current_state</code>: Current spin values for nodes in this block.</li> <li><code>neighbor_states</code>: Spin values of neighbors from all edges.</li> <li><code>neighbor_mask</code>: Boolean mask for valid positions in <code>neighbor_states</code>.</li> <li><code>model_params</code>: Tuple of <code>(edge_weights, node_biases)</code> for this block.</li> <li><code>runtime_params</code>: None.</li> <li><code>sampler_state</code>: None.</li> <li><code>key</code>: JAX random key for stochastic sampling.</li> </ul> <p>Returns:</p> <p>Tuple of <code>(new_block_state, None)</code> where new_block_state contains the sampled spin configuration.</p>"},{"location":"api/sample/#isax.sample.IsingSampler.initialize_state","title":"<code>initialize_state() -&gt; None</code>","text":"<p>Return None for stateless sampler.</p>"},{"location":"api/sample/#isax.sample.AnnealedIsingSampler","title":"<code>isax.sample.AnnealedIsingSampler</code>","text":"<p>Simulated annealing sampler with time-varying temperature.</p>"},{"location":"api/sample/#isax.sample.AnnealedIsingSampler.__init__","title":"<code>__init__(beta_fn: typing.Callable[[jaxtyping.Int[Array, '']], jaxtyping.Float[Array, '']])</code>","text":"<p>Arguments:</p> <ul> <li><code>beta_fn</code>: Function mapping timestep \\(t\\) to inverse temperature \\(\\beta(t)\\).     Can also curry beta arrays for more complex schedules.</li> </ul>"},{"location":"api/sample/#isax.sample.AnnealedIsingSampler.sample","title":"<code>sample(current_state: Int[Array, num_nodes], neighbor_states: Int[Array, 'num_nodes max_edges max_k-1'], neighbor_mask: Int[Array, 'num_nodes max_edges max_k-1'], model_params: tuple[jaxtyping.Float[Array, num_edges], jaxtyping.Float[Array, num_nodes]], runtime_params: None, sampler_state: Int[Array, ''], key: Key[Array, '']) -&gt; tuple[jaxtyping.Int[Array, num_nodes], jaxtyping.Int[Array, '']]</code>","text":"<p>Sample with temperature based on current timestep.</p> <p>Arguments:</p> <ul> <li><code>current_state</code>: Current spin values for nodes in this block.</li> <li><code>neighbor_states</code>: Spin values of neighbors from all edges.</li> <li><code>neighbor_mask</code>: Boolean mask for valid positions in <code>neighbor_states</code>.</li> <li><code>model_params</code>: Tuple of <code>(edge_weights, node_biases)</code> for this block.</li> <li><code>runtime_params</code>: Unused, provided for API compatibility.</li> <li><code>sampler_state</code>: Current timestep (integer scalar).</li> <li><code>key</code>: JAX random key for stochastic sampling.</li> </ul> <p>Returns:</p> <p>Tuple of <code>(new_block_state, new_sampler_state)</code> where new_sampler_state is incremented by 1.</p>"},{"location":"api/sample/#isax.sample.AnnealedIsingSampler.initialize_state","title":"<code>initialize_state() -&gt; Int[Array, '']</code>","text":"<p>Initialize time step to 0.</p>"},{"location":"api/sample/#sampling-utilities","title":"Sampling Utilities","text":""},{"location":"api/sample/#isax.sample.SamplingArgs","title":"<code>isax.sample.SamplingArgs</code>","text":"<p>Configuration and data for block-wise Gibbs sampling.</p>"},{"location":"api/sample/#isax.sample.SamplingArgs.__init__","title":"<code>__init__(gibbs_steps: int, blocks_to_sample: list[int], data: tuple[tuple, isax.block.EqxGraph]) -&gt; None</code>","text":"<p>Arguments:</p> <ul> <li><code>gibbs_steps</code>: Number of Gibbs sampling iterations to perform.</li> <li><code>blocks_to_sample</code>: List of block indices to update (e.g., <code>[0, 2]</code> updates     blocks 0 and 2).</li> <li><code>data</code>: Output from <code>BlockGraph.get_sampling_params()</code> containing adjacency     information and graph structure.</li> </ul>"},{"location":"api/sample/#isax.sample.sample_chain","title":"<code>isax.sample.sample_chain(block_states: list[jaxtyping.Int[Array, block_size]], samplers: list[isax.sample.AbstractSampler], model: IsingModel, sampling_args: SamplingArgs, key: Key[Array, '']) -&gt; list[jaxtyping.Int[Array, 'gibbs_steps block_size']]</code>","text":"<p>Run Gibbs sampling chain for specified number of steps.</p> <p>Arguments:</p> <ul> <li><code>block_states</code>: Initial spin states for each block.</li> <li><code>samplers</code>: List of sampler instances, one per block.</li> <li><code>model</code>: Energy model providing weights and biases.</li> <li><code>sampling_args</code>: Configuration with number of steps and blocks to sample.</li> <li><code>key</code>: JAX random key.</li> </ul> <p>Returns:</p> <p>List of arrays containing the history of block states over all Gibbs steps.</p>"},{"location":"examples/01_ising_model_physics/","title":"2D Ising Model Physics","text":"<pre><code>import equinox as eqx\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nfrom isax import (\n    BlockGraph,\n    Edge,\n    IsingModel,\n    IsingSampler,\n    magnetization_per_site,\n    Node,\n    sample_chain,\n    SamplingArgs,\n)\n</code></pre> <pre><code>L = 40\nnum_sites = L * L\nJ = 1.0\nh = 0.0\n\nnodes = [Node() for _ in range(num_sites)]\n\nedges, edge_weights = [], []\nfor x in range(L):\n    for y in range(L):\n        i = x * L + y\n        j = x * L + ((y + 1) % L)\n        k = ((x + 1) % L) * L + y\n        edges.append(Edge(nodes[i], nodes[j]))\n        edges.append(Edge(nodes[i], nodes[k]))\n        edge_weights.extend([J, J])\n\nedge_weights = jnp.array(edge_weights, dtype=float)\nnode_biases = jnp.full(num_sites, h, dtype=float)\n\neven_nodes, odd_nodes = [], []\nfor x in range(L):\n    for y in range(L):\n        (even_nodes if (x + y) % 2 == 0 else odd_nodes).append(nodes[x * L + y])\n\nblocks = [even_nodes, odd_nodes]\ngraph = BlockGraph(blocks, edges)\nparams = graph.get_sampling_params()\nsampling_args = SamplingArgs(\n    gibbs_steps=4500,\n    blocks_to_sample=[0, 1],\n    data=params,\n)\n\nedge_indices, edge_mask = graph.get_edge_structure()\n\nmodel = IsingModel(weights=edge_weights, biases=node_biases)\nsampler = IsingSampler()\n\nenergy_fn_jit = jax.jit(jax.vmap(model.energy, in_axes=(0, None, None)))\n\nT = jnp.linspace(0.9, 6.0, 30)\nbetas = 1.0 / T\n\nkey = jax.random.key(0)\n\nE_mean, M_mean, C = [], [], []\nall_samples = []\n\nsample_fn = eqx.filter_jit(sample_chain)\n\nfor beta, temp in zip(betas, T):\n    key, k_init, k_run = jax.random.split(key, 3)\n\n    init_state = [\n        jax.random.bernoulli(k_init, 0.5, (len(even_nodes),)).astype(jnp.int32) * 2 - 1,\n        jax.random.bernoulli(k_init, 0.5, (len(odd_nodes),)).astype(jnp.int32) * 2 - 1,\n    ]\n\n    model_with_beta = IsingModel(weights=beta * edge_weights, biases=beta * node_biases)\n\n    samples = sample_fn(\n        init_state, [sampler, sampler], model_with_beta, sampling_args, k_run\n    )\n    all_samples.append(samples)\n\n    spins = jnp.concatenate(samples, axis=-1)[70:]\n    spins = spins[::10]\n\n    energies = energy_fn_jit(spins, edge_indices, edge_mask) / num_sites\n    mags = magnetization_per_site(spins)\n\n    E_mean.append(jnp.mean(energies))\n    M_mean.append(jnp.mean(jnp.abs(mags)))\n    C.append((beta**2) * jnp.var(energies, ddof=1))\n\nE_mean, M_mean, C = jax.tree.map(jnp.array, (E_mean, M_mean, C))\n</code></pre> <pre><code>fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n\naxes[0].plot(T, E_mean, marker=\"o\")\naxes[0].set_xlabel(\"Temperature $T$\")\naxes[0].set_ylabel(\"Energy per spin\")\naxes[0].set_title(\"Energy vs. Temperature\")\naxes[0].grid(True)\n\naxes[1].plot(T, M_mean, marker=\"o\")\naxes[1].set_xlabel(\"Temperature $T$\")\naxes[1].set_ylabel(\"Magnetisation per spin\")\naxes[1].set_title(\"Magnetisation vs. Temperature\")\naxes[1].grid(True)\n\naxes[2].plot(T, C, marker=\"o\")\naxes[2].set_xlabel(\"Temperature $T$\")\naxes[2].set_ylabel(\"Specific heat Capacity per site\")\naxes[2].set_title(\"Specific Heat vs Temperature\")\naxes[2].axvline(2.269, lw=0.8, label=\"$T_c$ (Onsager, $L\\\\to\\\\infty$)\", color=\"red\")\naxes[2].legend()\naxes[2].grid(True)\n\nplt.show()\n</code></pre> <pre><code>time_points = [0, 1, 50, 70, 120, 310, 400]\nn_cols = len(time_points)\n\nidx_lowT = 0\nidx_critT = 8\nidx_highT = -1\n\nspin_histories = {}\nfor key_name, idx in [(\"cold\", idx_lowT), (\"crit\", idx_critT), (\"hot\", idx_highT)]:\n    spin_histories[key_name] = jnp.concatenate(all_samples[idx], axis=-1)\n\nfig, axes = plt.subplots(3, n_cols, figsize=(3 * n_cols, 10), constrained_layout=True)\n\ntitles = [rf\"t = {t}\" for t in time_points]\nrowlbl = [\n    rf\"$T={T[idx_lowT]:.2f}$\",\n    rf\"$T={T[idx_critT]:.2f}$\",\n    rf\"$T={T[idx_highT]:.1f}$\",\n]\n\nfor r, key in enumerate(spin_histories.keys()):\n    hist = spin_histories[key]\n    for c, t in enumerate(time_points):\n        ax = axes[r, c]\n        state = hist[t].reshape(L, L)\n        im = ax.imshow(state, vmin=-1, vmax=1, cmap=\"bwr\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if r == 0:\n            ax.set_title(titles[c])\n        if c == 0:\n            ax.set_ylabel(rowlbl[r])\n\ncbar = fig.colorbar(im, ax=axes, shrink=0.7, location=\"right\", label=\"Spin Value\")\n\nplt.suptitle(\"Ising spin configurations\")\nplt.show()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/02_fps/","title":"Flips Per Second","text":"<p>In this example we will be looking as Flips Per Second (FPS) as a metric for evaluating the speed of a Gibbs sampling program.</p> <pre><code>import time\n\nimport dwave_networkx\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom isax import (\n    BlockGraph,\n    Edge,\n    IsingModel,\n    IsingSampler,\n    Node,\n    sample_chain,\n    SamplingArgs,\n)\n</code></pre> <pre><code>def create_dwave_pegasus_graph(pegasus_size, key):\n    graph = dwave_networkx.pegasus_graph(pegasus_size)\n    coord_to_node = {coord: Node() for coord in graph.nodes}\n    nx.relabel_nodes(graph, coord_to_node, copy=False)\n    nodes = list(graph.nodes)\n    edges = [Edge(u, v) for u, v in graph.edges()]\n    # todo: dwave ships colorings already?\n    coloring = nx.coloring.greedy_color(graph, strategy=\"DSATUR\")\n    n_colors = max(coloring.values()) + 1\n    blocks = [[] for _ in range(n_colors)]\n    for node in graph.nodes:\n        blocks[coloring[node]].append(node)\n    block_graph = BlockGraph(blocks, edges)\n    key1, key2 = jax.random.split(key)\n    biases = jax.random.uniform(key1, (len(nodes),), minval=-0.1, maxval=0.1)\n    weights = jax.random.uniform(key2, (len(edges),), minval=-0.1, maxval=0.1)\n\n    model = IsingModel(weights=weights, biases=biases)\n\n    print(\n        f\"Created graph with {len(nodes)} nodes, {len(edges)} edges, {n_colors} blocks\"\n    )\n\n    return model, block_graph, nodes, blocks\n</code></pre> <pre><code>def time_sampling(\n    model, block_graph, nodes, blocks, chain_len, batch_size, n_reps, device\n):\n    key = jax.random.key(42)\n\n    (adjs, masks, edge_infos), eqx_graph = block_graph.get_sampling_params()\n\n    samplers = [IsingSampler() for _ in range(len(blocks))]\n\n    sampling_args = SamplingArgs(\n        gibbs_steps=chain_len,\n        blocks_to_sample=list(range(len(blocks))),\n        adjs=adjs,\n        masks=masks,\n        edge_info=edge_infos,\n        eqx_graph=eqx_graph,\n    )\n\n    def sample_batch(key):\n        keys = jax.random.split(key, batch_size)\n\n        def sample_single(single_key):\n            k_init, k_run = jax.random.split(single_key)\n\n            init_state = []\n            for block in blocks:\n                block_state = (\n                    jax.random.bernoulli(k_init, 0.5, (len(block),)).astype(jnp.int32)\n                    * 2\n                    - 1\n                )\n                init_state.append(block_state)\n\n            samples = sample_chain(init_state, samplers, model, sampling_args, k_run)\n            return samples\n\n        return jax.vmap(sample_single)(keys)\n\n    jit_sample_batch = jax.jit(sample_batch, device=device)\n\n    keys = jax.random.split(key, n_reps)\n\n    start_time = time.time()\n    _ = jax.block_until_ready(jit_sample_batch(keys[0]))\n    time_with_compile = time.time() - start_time\n\n    start_time = time.time()\n    for i in range(n_reps):\n        _ = jax.block_until_ready(jit_sample_batch(keys[i]))\n    trials_time = time.time() - start_time\n\n    time_without_compile = trials_time / n_reps\n\n    thruput = chain_len * batch_size * len(nodes)\n    flips_per_ns = thruput / (time_without_compile * 1e9)\n\n    print(f\"chain_len: {chain_len}, batch_size: {batch_size}\")\n    print(\n        f\"Time with compile: {time_with_compile:.4f}s, \"\n        f\"time without compile: {time_without_compile:.4f}s, \"\n        f\"flips per ns: {flips_per_ns:.4f}, thruput: {thruput}\"\n    )\n\n    return flips_per_ns\n</code></pre> <pre><code>pegasus_size = 14\nchain_len = 1000\nn_reps = 2\n\nbatch_sizes = [1, 4, 16, 64, 128, 256, 1024]\n\ntry:\n    device_gpu = jax.devices(\"cuda\")[0]\n    has_gpu = True\nexcept Exception as _:\n    has_gpu = False\n\ndevice_cpu = jax.devices(\"cpu\")[0]\n\n# Create the graph once and reuse it\nkey = jax.random.key(42)\nmodel, block_graph, nodes, blocks = create_dwave_pegasus_graph(pegasus_size, key)\n\nflips_per_ns_cpu = []\nfor batch_size in batch_sizes:\n    val = time_sampling(\n        model, block_graph, nodes, blocks, chain_len, batch_size, n_reps, device_cpu\n    )\n    flips_per_ns_cpu.append(val)\n\nif has_gpu:\n    flips_per_ns_gpu = []\n    for batch_size in batch_sizes:\n        val = time_sampling(\n            model, block_graph, nodes, blocks, chain_len, batch_size, n_reps, device_gpu\n        )\n        flips_per_ns_gpu.append(val)\n</code></pre> <pre><code>Created Pegasus graph with 4264 nodes, 30404 edges, 4 color blocks\nchain_len: 1000, batch_size: 1\nTime with compile: 0.5638s, time without compile: 0.2302s, flips per ns: 0.0185, thruput: 4264000\nchain_len: 1000, batch_size: 4\nTime with compile: 0.9512s, time without compile: 0.5929s, flips per ns: 0.0288, thruput: 17056000\nchain_len: 1000, batch_size: 16\nTime with compile: 1.6824s, time without compile: 1.3140s, flips per ns: 0.0519, thruput: 68224000\nchain_len: 1000, batch_size: 64\nTime with compile: 2.9053s, time without compile: 2.5344s, flips per ns: 0.1077, thruput: 272896000\nchain_len: 1000, batch_size: 128\nTime with compile: 4.1339s, time without compile: 3.7625s, flips per ns: 0.1451, thruput: 545792000\nchain_len: 1000, batch_size: 256\nTime with compile: 5.6201s, time without compile: 5.2584s, flips per ns: 0.2076, thruput: 1091584000\nchain_len: 1000, batch_size: 1024\nTime with compile: 15.3236s, time without compile: 15.0730s, flips per ns: 0.2897, thruput: 4366336000\nchain_len: 1000, batch_size: 1\nTime with compile: 1.2708s, time without compile: 0.0285s, flips per ns: 0.1498, thruput: 4264000\nchain_len: 1000, batch_size: 4\nTime with compile: 1.2622s, time without compile: 0.0339s, flips per ns: 0.5034, thruput: 17056000\nchain_len: 1000, batch_size: 16\nTime with compile: 1.4971s, time without compile: 0.0455s, flips per ns: 1.5007, thruput: 68224000\nchain_len: 1000, batch_size: 64\nTime with compile: 1.2715s, time without compile: 0.0641s, flips per ns: 4.2579, thruput: 272896000\nchain_len: 1000, batch_size: 128\nTime with compile: 1.2462s, time without compile: 0.0933s, flips per ns: 5.8480, thruput: 545792000\nchain_len: 1000, batch_size: 256\nTime with compile: 1.3404s, time without compile: 0.1517s, flips per ns: 7.1960, thruput: 1091584000\nchain_len: 1000, batch_size: 1024\nTime with compile: 1.7359s, time without compile: 0.4824s, flips per ns: 9.0515, thruput: 4366336000\n</code></pre> <pre><code>plt.figure(figsize=(6, 6))\nif has_gpu:\n    plt.plot(batch_sizes, flips_per_ns_gpu, label=\"isax GPU\", marker=\"o\")\nplt.plot(batch_sizes, flips_per_ns_cpu, label=\"isax CPU\", marker=\"s\")\nplt.legend()\nplt.xlabel(\"Batch size\")\nplt.xscale(\"log\")\nplt.yscale(\"log\")\nplt.ylabel(\"Flips per ns\")\nplt.show()\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"examples/03_ising_thermodynamics/","title":"Thermodynamic Properties of Ising Models","text":"<p>Adapted from https://cossio.github.io/IsingModels.jl/stable/literate/wolff/. </p> <pre><code>import equinox as eqx\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom isax import (\n    BlockGraph,\n    Edge,\n    IsingModel,\n    IsingSampler,\n    magnetization_per_site,\n    Node,\n    sample_chain,\n    SamplingArgs,\n)\nfrom scipy.special import ellipe, ellipk\n</code></pre> <pre><code>def create_2d_ising_graph(L, J=1.0, h=0.0):\n    num_sites = L * L\n    nodes = [Node() for _ in range(num_sites)]\n\n    edges, edge_weights = [], []\n    for x in range(L):\n        for y in range(L):\n            i = x * L + y\n            j = x * L + ((y + 1) % L)\n            k = ((x + 1) % L) * L + y\n            edges.append(Edge(nodes[i], nodes[j]))\n            edges.append(Edge(nodes[i], nodes[k]))\n            edge_weights.extend([J, J])\n\n    edge_weights = jnp.array(edge_weights, dtype=float)\n    node_biases = jnp.full(num_sites, h, dtype=float)\n\n    even_nodes, odd_nodes = [], []\n    for x in range(L):\n        for y in range(L):\n            (even_nodes if (x + y) % 2 == 0 else odd_nodes).append(nodes[x * L + y])\n\n    blocks = [even_nodes, odd_nodes]\n    graph = BlockGraph(blocks, edges)\n\n    return graph, edge_weights, node_biases, edges\n\n\nbeta_c = np.log(1 + np.sqrt(2)) / 2\nT_c = 1.0 / beta_c\n\n\ndef onsager_magnetization(beta):\n    beta = np.asarray(beta)\n    csch_val = 1.0 / np.sinh(2 * beta)\n    return np.where(\n        beta &gt;= beta_c, np.power(np.maximum(1 - csch_val**4, 0), 1 / 8), 0.0\n    )\n\n\ndef onsager_internal_energy(beta):\n    beta = np.asarray(beta)\n    k = 2 * np.tanh(2 * beta) / np.cosh(2 * beta)\n    j = 2 * np.tanh(2 * beta) ** 2 - 1\n    K = ellipk(k**2)\n    return -1 / np.tanh(2 * beta) * (1 + 2 / np.pi * j * K)\n\n\ndef onsager_heat_capacity(beta):\n    beta = np.asarray(beta)\n    k = 2 * np.tanh(2 * beta) / np.cosh(2 * beta)\n    K = ellipk(k**2)\n    E = ellipe(k**2)\n    j = 2 * np.tanh(2 * beta) ** 2 - 1\n    return (\n        beta**2\n        * (1 / np.tanh(2 * beta)) ** 2\n        * (2 / np.pi)\n        * (((j - 0.5) ** 2 + 7 / 4) * K - 2 * E - (1 - j) * np.pi / 2)\n    )\n</code></pre>"},{"location":"examples/03_ising_thermodynamics/#magnetization-vs-temperature-for-different-system-sizes","title":"Magnetization vs Temperature for Different System Sizes","text":"<pre><code>T = jnp.linspace(1.5, 3.0, 40)\nbetas = 1.0 / T\nto_sample = [\n    (4, \"orange\", \"L=4\"),\n    (8, \"green\", \"L=8\"),\n    (16, \"blue\", \"L=16\"),\n    (32, \"red\", \"L=32\"),\n]\n\nkey = jax.random.key(42)\nsample_fn = eqx.filter_jit(sample_chain)\n\nresults = {}\n\nfor L, color, label in to_sample:\n    print(f\"Simulating {label}\")\n    graph, edge_weights, node_biases, edges = create_2d_ising_graph(L)\n    edge_indices, edge_mask = graph.get_edge_structure()\n\n    params = graph.get_sampling_params()\n    sampling_args = SamplingArgs(\n        gibbs_steps=4000,\n        blocks_to_sample=[0, 1],\n        data=params,\n    )\n\n    model = IsingModel(weights=edge_weights, biases=node_biases)\n    sampler = IsingSampler()\n    energy_fn_jit = eqx.filter_jit(model.energy)\n\n    M_avg, E_avg, C_avg = [], [], []\n    M_std, E_std, C_std = [], [], []\n\n    for beta, temp in zip(betas, T):\n        key, k_init, k_run = jax.random.split(key, 3)\n\n        num_even = len([n for i, n in enumerate(graph.nodes) if i % 2 == 0])\n        num_odd = L * L - num_even\n\n        init_state = [\n            jax.random.choice(k_init, jnp.array([1, -1]), shape=(num_even,)),\n            jax.random.choice(k_init, jnp.array([1, -1]), shape=(num_odd,)),\n        ]\n\n        model_with_beta = IsingModel(\n            weights=beta * edge_weights, biases=beta * node_biases\n        )\n\n        samples = sample_fn(\n            init_state, [sampler, sampler], model_with_beta, sampling_args, k_run\n        )\n\n        equilibration = 500\n        spins = jnp.concatenate(samples, axis=-1)[equilibration:]\n        spins = spins[::5]\n\n        mags = jnp.abs(magnetization_per_site(spins))\n        energies = jax.vmap(energy_fn_jit, in_axes=(0, None, None))(\n            spins, edge_indices, edge_mask\n        ) / (L * L)\n\n        M_avg.append(jnp.mean(mags))\n        M_std.append(jnp.std(mags))\n        E_avg.append(jnp.mean(energies))\n        E_std.append(jnp.std(energies))\n        C_avg.append(beta**2 * jnp.var(energies * L * L, ddof=1) / (L * L))\n\n    results[(L, color, label)] = {\n        \"M_avg\": jnp.array(M_avg),\n        \"M_std\": jnp.array(M_std),\n        \"E_avg\": jnp.array(E_avg),\n        \"E_std\": jnp.array(E_std),\n        \"C_avg\": jnp.array(C_avg),\n    }\n</code></pre> <pre><code>Simulating L=4\nSimulating L=8\nSimulating L=16\nSimulating L=32\n</code></pre> <pre><code>fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nfor (L, color, label), data in results.items():\n    axes[0].errorbar(\n        T,\n        data[\"M_avg\"],\n        yerr=data[\"M_std\"] / 2,\n        fmt=\"o\",\n        color=color,\n        label=label,\n        markersize=4,\n        linestyle=\"None\",\n    )\n    axes[1].errorbar(\n        T,\n        data[\"E_avg\"],\n        yerr=data[\"E_std\"] / 2,\n        fmt=\"o-\",\n        color=color,\n        label=label,\n        markersize=4,\n    )\n    axes[2].plot(\n        T, data[\"C_avg\"], \"o\", color=color, label=label, markersize=4, linestyle=\"None\"\n    )\n\nT_theory = np.linspace(T.min(), T.max(), 100)\nbeta_theory = 1.0 / T_theory\nM_theory = onsager_magnetization(beta_theory)\nE_theory = onsager_internal_energy(beta_theory)\nC_theory = onsager_heat_capacity(beta_theory)\n\naxes[0].plot(T_theory, M_theory, \"k-\", label=\"Exact\", linewidth=2)\naxes[0].set_xlabel(\"Temperature\")\naxes[0].set_ylabel(\"Magnetization\")\naxes[0].set_title(\"Magnetization vs Temperature\")\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(T_theory, E_theory, \"k-\", label=\"Exact\", linewidth=2)\naxes[1].set_xlabel(\"Temperature\")\naxes[1].set_ylabel(\"Energy per spin\")\naxes[1].set_title(\"Internal Energy vs Temperature\")\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\naxes[2].plot(T_theory, C_theory, \"k-\", label=\"Exact\", linewidth=2)\naxes[2].axvline(T_c, color=\"gray\", linestyle=\"--\", alpha=0.5)\naxes[2].set_xlabel(\"Temperature\")\naxes[2].set_ylabel(\"Heat Capacity\")\naxes[2].set_title(\"Heat Capacity vs Temperature\")\naxes[2].legend()\naxes[2].grid(True, alpha=0.3)\naxes[2].set_ylim(0, 3)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"examples/03_ising_thermodynamics/#correlation-length-analysis","title":"Correlation Length Analysis","text":"<pre><code># todo: fix\n\n# def compute_correlation_function(spins, max_r=None):\n#     L = int(jnp.sqrt(spins.shape[-1]))\n#     spins_2d = spins.reshape(-1, L, L)\n\n#     if max_r is None:\n#         max_r = L // 4\n#     else:\n#         max_r = min(max_r, L // 4)\n\n#     correlations = []\n\n#     mean_mag = jnp.mean(spins_2d)\n\n#     for r in range(1, max_r + 1):\n#         corr_h = jnp.mean(spins_2d[:, :, :] * jnp.roll(spins_2d, r, axis=2))\n#         corr_v = jnp.mean(spins_2d[:, :, :] * jnp.roll(spins_2d, r, axis=1))\n#         corr = (corr_h + corr_v) / 2 - mean_mag**2\n#         correlations.append(corr)\n\n#     return jnp.array(correlations)\n\n\n# L = 32\n# graph, edge_weights, node_biases, edges = create_2d_ising_graph(L, 1)\n\n# params = graph.get_sampling_params()\n# sampling_args = SamplingArgs(\n#     gibbs_steps=2000,\n#     blocks_to_sample=[0, 1],\n#     data=params,\n# )\n\n# model = IsingModel(weights=edge_weights, biases=node_biases)\n# sampler = IsingSampler()\n\n# temperatures = np.linspace(1.5, 3.0, 10)\n\n# correlation_results = {}\n\n# for temp in temperatures:\n#     print(f\"Computing correlations at T={temp:.2f}\")\n#     beta = 1.0 / temp\n#     key, k_init, k_run = jax.random.split(key, 3)\n\n#     num_even = L * L // 2\n#     num_odd = L * L - num_even\n\n#     init_state = [\n#         jax.random.choice(k_init, jnp.array([1, -1]), shape=(num_even,)),\n#         jax.random.choice(k_init, jnp.array([1, -1]), shape=(num_odd,)),\n#     ]\n\n#     model_with_beta = IsingModel(weights=beta * edge_weights,\n#                           biases=beta * node_biases)\n\n#     samples = sample_fn(\n#         init_state, [sampler, sampler], model_with_beta, sampling_args, k_run\n#     )\n\n#     spins = jnp.concatenate(samples, axis=-1)[1000::10]\n#     correlations = compute_correlation_function(spins)\n\n#     correlation_results[temp] = correlations\n</code></pre> <pre><code># fig, ax = plt.subplots(figsize=(7, 4))\n\n# for (temp), correlations in correlation_results.items():\n#     r = jnp.arange(1, len(correlations) + 1)\n#     label = f\"T={temp:.2f}\"\n#     ax.plot(r, jnp.abs(correlations), \"o-\", label=label)\n\n# ax.set_xlabel(\"Distance\")\n# ax.set_ylabel(\"|C(r)|\")\n# ax.set_title(\"Spin-Spin Correlation Function\")\n# ax.legend()\n# ax.grid(True, alpha=0.3)\n# plt.show()\n</code></pre> <pre><code># todo: add ac analysis\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/04_paoa_optimization/","title":"Probabilistic Approximate Optimization Algorithm","text":"<p>In this example, we recreate Figure 3(c) of https://arxiv.org/abs/2507.07420.</p> <pre><code>import equinox as eqx\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom isax import (\n    AnnealedIsingSampler,\n    BlockGraph,\n    Edge,\n    IsingModel,\n    Node,\n    sample_chain,\n    SamplingArgs,\n)\nfrom scipy.optimize import minimize\n</code></pre> <pre><code>L = 6\nnum_sites = L * L * L\nnodes = [Node() for _ in range(num_sites)]\n\nedges, edge_weights = [], []\nfor x in range(L):\n    for y in range(L):\n        for z in range(L):\n            i = x * L * L + y * L + z\n            j = ((x + 1) % L) * L * L + y * L + z\n            k = x * L * L + ((y + 1) % L) * L + z\n            l = x * L * L + y * L + ((z + 1) % L)\n            edges.append(Edge(nodes[i], nodes[j]))\n            edges.append(Edge(nodes[i], nodes[k]))\n            edges.append(Edge(nodes[i], nodes[l]))\n            J = np.random.choice([-1, 1])\n            edge_weights.extend([J, J, J])\n\nedge_weights = jnp.array(edge_weights)\nnode_biases = jnp.zeros(num_sites)\n\neven_nodes, odd_nodes = [], []\nfor x in range(L):\n    for y in range(L):\n        for z in range(L):\n            (even_nodes if (x + y + z) % 2 == 0 else odd_nodes).append(\n                nodes[x * L * L + y * L + z]\n            )\n\nblocks = [even_nodes, odd_nodes]\n</code></pre> <pre><code>num_beta = 5\nnum_mcs = 720\nnum_exps = 100_00\ninit_betas = jnp.ones(num_beta) * 2\n\ngraph = BlockGraph(blocks, edges)\nparams = graph.get_sampling_params()\nedge_indices, edge_mask = graph.get_edge_structure()\nmodel = IsingModel(weights=edge_weights, biases=node_biases)\n</code></pre> <pre><code>def _sample_energy(betas, key):\n    betas = jnp.clip(betas, 1e-8)\n    beta_schedule = jnp.repeat(betas, num_mcs)\n\n    samplers = [\n        AnnealedIsingSampler(lambda t, schedule=beta_schedule: schedule[t]),\n        AnnealedIsingSampler(lambda t, schedule=beta_schedule: schedule[t]),\n    ]\n\n    sampling_args = SamplingArgs(\n        gibbs_steps=num_beta * num_mcs - 1, blocks_to_sample=[0, 1], data=params\n    )\n\n    key, k_init, k_run = jax.random.split(key, 3)\n    init_state = [\n        jax.random.bernoulli(k_init, 0.5, (len(even_nodes),)).astype(jnp.int32) * 2 - 1,\n        jax.random.bernoulli(k_init, 0.5, (len(odd_nodes),)).astype(jnp.int32) * 2 - 1,\n    ]\n\n    model_with_beta = IsingModel(weights=edge_weights, biases=node_biases)\n\n    samples = sample_chain(init_state, samplers, model_with_beta, sampling_args, k_run)\n    final_states = jax.tree.map(lambda x: x[-1], samples)\n    final_state = jnp.concatenate(final_states)\n    energy = model.energy(final_state, edge_indices, edge_mask)\n    return energy\n\n\n@eqx.filter_jit\ndef sample_energy(betas, key):\n    keys = jax.random.split(key, num_exps)\n    energies = eqx.filter_vmap(_sample_energy, in_axes=(None, 0))(betas, keys)\n    return jnp.mean(energies)\n</code></pre> <pre><code>def optimise_sample_energy(init_betas, key, tol=1e-3, maxiter=50):\n    energy_trace = []\n    key_box = [key]\n\n    def objective(betas_np):\n        key_box[0], subkey = jax.random.split(key_box[0])\n        energy = sample_energy(jnp.asarray(betas_np), subkey)\n        val = float(energy)\n        energy_trace.append(val)\n        return val\n\n    result = minimize(\n        objective,\n        init_betas,\n        method=\"COBYLA\",\n        options={\"maxiter\": maxiter, \"tol\": tol},\n    )\n    return result, energy_trace\n\n\nkey0 = jax.random.key(0)\nres, energy_trace = optimise_sample_energy(init_betas, key0)\nprint(\"Optimal betas :\", res.x)\nprint(\"Final energy  :\", res.fun)\n</code></pre> <pre><code>Optimal betas : [0.63426977 0.75867339 0.77075641 1.51255569 3.30873154]\nFinal energy  : -390.773193359375\n</code></pre> <pre><code>plt.plot(energy_trace)\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Energy\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <pre><code>plt.plot(init_betas, marker=\"o\", label=\"Initial Betas\")\nplt.plot(res.x, marker=\"o\", label=\"Final Betas\")\nplt.xlabel(\"Layers\")\nplt.ylabel(\"Beta\")\nplt.legend()\nplt.show()\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"examples/05_ising_mnist/","title":"Sparse Ising Model on MNIST","text":"<pre><code>import equinox as eqx\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport optax\nfrom isax import (\n    BlockGraph,\n    Edge,\n    IsingModel,\n    IsingSampler,\n    Node,\n    sample_chain,\n    SamplingArgs,\n)\nfrom torchvision import datasets\n</code></pre> <pre><code>train_dataset = datasets.MNIST(root=\"/tmp/mnist\", train=True, download=True)\ntest_dataset = datasets.MNIST(root=\"/tmp/mnist\", train=False, download=True)\n\ntrain_images = train_dataset.data.numpy()\ntrain_labels = train_dataset.targets.numpy()\ntest_images = test_dataset.data.numpy()\ntest_labels = test_dataset.targets.numpy()\n\n# Binarize images\ntrain_images = (train_images &gt; 127).astype(np.int32)\ntest_images = (test_images &gt; 127).astype(np.int32)\n\n# Flatten to vectors\ntrain_images = train_images.reshape(train_images.shape[0], -1)\ntest_images = test_images.reshape(test_images.shape[0], -1)\n\ntarget_classes = [0, 1]\ntrain_mask = np.isin(train_labels, target_classes)\ntest_mask = np.isin(test_labels, target_classes)\n\ntrain_images = jnp.array(train_images[train_mask])\ntrain_labels = jnp.array(train_labels[train_mask])\ntest_images = jnp.array(test_images[test_mask])\ntest_labels = jnp.array(test_labels[test_mask])\n\nprint(f\"Train: {train_images.shape}, Test: {test_images.shape}\")\n</code></pre> <pre><code>Train: (12665, 784), Test: (2115, 784)\n</code></pre> <pre><code>fig, axes = plt.subplots(1, 5, figsize=(10, 2))\nfor i, ax in enumerate(axes):\n    ax.imshow(train_images[i].reshape(28, 28), cmap=\"gray\")\n    ax.set_title(f\"Label: {train_labels[i]}\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>n_visible = 28 * 28\nn_hidden = 200\nn_total = n_visible + n_hidden\n\nk_connections = 50  # each hidden unit connects to 50 random visible units\n\nkey = jax.random.key(42)\n\nvisible_nodes = [Node() for _ in range(n_visible)]\nhidden_nodes = [Node() for _ in range(n_hidden)]\n\nedges = []\nkey, subkey = jax.random.split(key)\nfor h_idx, h in enumerate(hidden_nodes):\n    visible_indices = np.random.choice(n_visible, size=(k_connections,), replace=False)\n    for v_idx in visible_indices:\n        edges.append(Edge(visible_nodes[int(v_idx)], h))\n\nn_edges = len(edges)\nprint(f\"Sparse: {n_edges} (vs {n_visible * n_hidden} for RBM)\")\nprint(f\"Sparsity: {n_edges / (n_visible * n_hidden) * 100:.1f}%\")\n\nblocks = [visible_nodes, hidden_nodes]\ngraph = BlockGraph(blocks, edges)\nparams = graph.get_sampling_params()\nedge_indices, edge_mask = graph.get_edge_structure()\n</code></pre> <pre><code>Sparse: 10000 (vs 156800 for RBM)\nSparsity: 6.4%\n</code></pre> <pre><code>key, subkey = jax.random.split(key)\ninit_weights = jax.random.normal(subkey, (n_edges,)) * 0.01\n\ndata_mean = jnp.mean(train_images, axis=0)\neps = 1e-6\nvisible_biases = jnp.log((data_mean + eps) / (1 - data_mean + eps)) * 0.5\nhidden_biases = jnp.zeros(n_hidden)\ninit_biases = jnp.concatenate([visible_biases, hidden_biases])\n\nmodel = IsingModel(weights=init_weights, biases=init_biases)\n</code></pre> <pre><code>@jax.jit\ndef data_to_spins(data):\n    return 2 * data - 1\n\n\n@jax.jit\ndef spins_to_data(spins):\n    return (spins + 1) // 2\n\n\nsampler = IsingSampler()\n\n# Positive phase: only sample hidden (block 1), visible clamped\npos_sampling_args = SamplingArgs(\n    gibbs_steps=200,\n    blocks_to_sample=[1],\n    data=params,\n)\n\n# Negative phase: sample both blocks freely\nneg_sampling_args = SamplingArgs(\n    gibbs_steps=400,\n    blocks_to_sample=[0, 1],\n    data=params,\n)\n</code></pre> <pre><code>def cd_loss(\n    weights,\n    biases,\n    data_batch,\n    key,\n):\n    model = IsingModel(weights=weights, biases=biases)\n    batch_size = data_batch.shape[0]\n\n    visible_spins = data_to_spins(data_batch)\n\n    key, subkey = jax.random.split(key)\n    hidden_init = jax.random.choice(subkey, jnp.array([-1, 1]), (batch_size, n_hidden))\n\n    def sample_positive(visible, hidden, k):\n        states = sample_chain(\n            [visible, hidden],\n            [sampler, sampler],\n            model,\n            pos_sampling_args,\n            jax.random.fold_in(k, 0),\n        )\n        return states[0][-1], states[1][-1]\n\n    key, subkey = jax.random.split(key)\n    keys = jax.random.split(subkey, batch_size)\n    v_pos, h_pos = jax.vmap(sample_positive)(visible_spins, hidden_init, keys)\n\n    def sample_negative(visible, hidden, k):\n        states = sample_chain(\n            [visible, hidden],\n            [sampler, sampler],\n            model,\n            neg_sampling_args,\n            jax.random.fold_in(k, 1),\n        )\n        return states[0][-1], states[1][-1]\n\n    key, subkey = jax.random.split(key)\n    keys = jax.random.split(subkey, batch_size)\n    v_neg, h_neg = jax.vmap(sample_negative)(v_pos, h_pos, keys)\n\n    def compute_energy(v, h):\n        state = jnp.concatenate([v, h])\n        return model.energy(state, edge_indices, edge_mask)\n\n    e_pos = jax.vmap(compute_energy)(v_pos, h_pos)\n    e_neg = jax.vmap(compute_energy)(v_neg, h_neg)\n\n    return jnp.mean(e_pos) - jnp.mean(e_neg)\n\n\n@eqx.filter_jit\ndef cd_step(weights, biases, opt_state, optimizer, data_batch, key):\n    loss, (grad_w, grad_b) = jax.value_and_grad(cd_loss, argnums=(0, 1))(\n        weights, biases, data_batch, key\n    )\n\n    updates_w, opt_state_w = optimizer.update(grad_w, opt_state[0], weights)\n    updates_b, opt_state_b = optimizer.update(grad_b, opt_state[1], biases)\n\n    new_weights = optax.apply_updates(weights, updates_w)\n    new_biases = optax.apply_updates(biases, updates_b)\n\n    return new_weights, new_biases, (opt_state_w, opt_state_b), loss\n</code></pre> <pre><code>batch_size = 64\nn_epochs = 12\nlearning_rate = 0.005\n\noptimizer = optax.adam(learning_rate=learning_rate)\nopt_state = (optimizer.init(model.weights), optimizer.init(model.biases))\n\nweights = model.weights\nbiases = model.biases\nlosses = []\n\nn_batches = len(train_images) // batch_size\n\nfor epoch in range(n_epochs):\n    key, subkey = jax.random.split(key)\n    perm = jax.random.permutation(subkey, len(train_images))\n    train_images_shuffled = train_images[perm]\n\n    epoch_loss = 0.0\n    for batch_idx in range(n_batches):\n        batch = train_images_shuffled[\n            batch_idx * batch_size : (batch_idx + 1) * batch_size\n        ]\n\n        key, subkey = jax.random.split(key)\n        weights, biases, opt_state, loss = cd_step(\n            weights, biases, opt_state, optimizer, batch, subkey\n        )\n        epoch_loss += loss\n\n    avg_loss = epoch_loss / n_batches\n    losses.append(float(avg_loss))\n    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.4f}\")\n</code></pre> <pre><code>Epoch 1/12, Loss: -12.9094\nEpoch 2/12, Loss: -13.1847\nEpoch 3/12, Loss: -9.7431\nEpoch 4/12, Loss: -7.0727\nEpoch 5/12, Loss: -5.5887\nEpoch 6/12, Loss: -4.1621\nEpoch 7/12, Loss: -2.7466\nEpoch 8/12, Loss: -2.2553\nEpoch 9/12, Loss: -1.7346\nEpoch 10/12, Loss: -1.2224\nEpoch 11/12, Loss: -1.0403\nEpoch 12/12, Loss: -0.3680\n</code></pre> <pre><code>gen_sampling_args = SamplingArgs(\n    gibbs_steps=400,\n    blocks_to_sample=[0, 1],\n    data=params,\n)\n\ntrained_model = IsingModel(weights=weights, biases=biases)\nsample_fn = eqx.filter_jit(sample_chain)\n\n\n@eqx.filter_jit\n@eqx.filter_vmap\ndef generate_sample(key):\n    k1, k2, k_run = jax.random.split(key, 3)\n    init_visible = jax.random.choice(k1, jnp.array([-1, 1]), (n_visible,))\n    init_hidden = jax.random.choice(k2, jnp.array([-1, 1]), (n_hidden,))\n\n    samples = sample_fn(\n        [init_visible, init_hidden],\n        [sampler, sampler],\n        trained_model,\n        gen_sampling_args,\n        k_run,\n    )\n    return samples[0][-1]\n</code></pre> <pre><code>n_gen = 16\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, n_gen)\ngenerated_spins = generate_sample(keys)\ngenerated = spins_to_data(generated_spins)\n\nn_cols, n_rows = 4, 4\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(8, 8))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(generated[i].reshape(28, 28), cmap=\"gray\")\n    ax.axis(\"off\")\nplt.suptitle(\"Generated Samples\", fontsize=14)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>half_pixels = 14 * 28  # Top 14 rows\ntop_visible_nodes = visible_nodes[:half_pixels]\nbottom_visible_nodes = visible_nodes[half_pixels:]\n\nclamped_blocks = [top_visible_nodes, bottom_visible_nodes, hidden_nodes]\nclamped_graph = BlockGraph(clamped_blocks, edges)\nclamped_params = clamped_graph.get_sampling_params()\n\n# Only sample bottom visible (block 1) and hidden (block 2), clamp top (block 0)\nclamped_sampling_args = SamplingArgs(\n    gibbs_steps=500,\n    blocks_to_sample=[1, 2],\n    data=clamped_params,\n)\n</code></pre> <pre><code>n_test = 8\ntest_batch = test_images[:n_test]\n\n\n@jax.jit\n@jax.vmap\ndef complete_image(visible_data, key):\n    k1, k2, k_run = jax.random.split(key, 3)\n\n    visible_spins = data_to_spins(visible_data).astype(jnp.int32)\n    top_spins = visible_spins[:half_pixels]\n\n    bottom_init = jax.random.choice(k1, jnp.array([-1, 1]), (n_visible - half_pixels,))\n    hidden_init = jax.random.choice(k2, jnp.array([-1, 1]), (n_hidden,))\n\n    states = sample_fn(\n        [top_spins, bottom_init, hidden_init],\n        [sampler, sampler, sampler],\n        trained_model,\n        clamped_sampling_args,\n        k_run,\n    )\n\n    full_spins = jnp.concatenate([states[0][-1], states[1][-1]])\n    return spins_to_data(full_spins)\n\n\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, n_test)\ncompleted = complete_image(test_batch, keys)\n\nfig, axes = plt.subplots(3, n_test, figsize=(16, 6))\nfor i in range(n_test):\n    axes[0, i].imshow(test_batch[i].reshape(28, 28), cmap=\"gray\")\n    axes[0, i].axis(\"off\")\n    if i == 0:\n        axes[0, i].set_ylabel(\"Original\", fontsize=12)\n\n    masked = test_batch[i].reshape(28, 28).copy()\n    masked = jnp.array(masked).at[14:, :].set(0.5)\n    axes[1, i].imshow(masked, cmap=\"gray\", vmin=0, vmax=1)\n    axes[1, i].axhline(14, color=\"red\", linewidth=2)\n    axes[1, i].axis(\"off\")\n    if i == 0:\n        axes[1, i].set_ylabel(\"Input (top half)\", fontsize=12)\n\n    axes[2, i].imshow(completed[i].reshape(28, 28), cmap=\"gray\")\n    axes[2, i].axhline(14, color=\"red\", linewidth=2)\n    axes[2, i].axis(\"off\")\n    if i == 0:\n        axes[2, i].set_ylabel(\"Completed\", fontsize=12)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>@jax.jit\n@jax.vmap\ndef compute_data_energy(visible_data, key):\n    visible_spins = data_to_spins(visible_data)\n    hidden = jax.random.choice(key, jnp.array([-1, 1]), (n_hidden,))\n\n    states = sample_fn(\n        [visible_spins, hidden],\n        [sampler, sampler],\n        trained_model,\n        pos_sampling_args,\n        key,\n    )\n\n    state = jnp.concatenate([states[0][-1], states[1][-1]])\n    return trained_model.energy(state, edge_indices, edge_mask)\n\n\nn = 1000\nkey, subkey = jax.random.split(key)\ndata_keys = jax.random.split(subkey, n)\ndata_energies = compute_data_energy(train_images[:n], data_keys)\n\nkey, subkey = jax.random.split(key)\nnoise_keys = jax.random.split(subkey, n)\nrandom_data = jax.random.bernoulli(subkey, 0.5, (n, n_visible)).astype(jnp.int32)\nnoise_energies = compute_data_energy(random_data, noise_keys)\n\nprint(f\"Data energy: {jnp.mean(data_energies):.2f} +/- {jnp.std(data_energies):.2f}\")\nprint(\n    f\"Random energy: {jnp.mean(noise_energies):.2f} +/- {jnp.std(noise_energies):.2f}\"\n)\n\nplt.figure(figsize=(8, 4))\nplt.hist(data_energies, bins=30, alpha=0.7, label=\"Data\", density=True)\nplt.hist(noise_energies, bins=30, alpha=0.7, label=\"Random\", density=True)\nplt.xlabel(\"Energy\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.show()\n</code></pre> <pre><code>Data energy: -3175.77 +/- 51.00\nRandom energy: -332.40 +/- 123.59\n</code></pre> <pre><code>\n</code></pre>"}]}